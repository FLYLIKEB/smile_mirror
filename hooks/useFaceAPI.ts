import { useRef, useState, useCallback } from 'react';
import * as faceapi from 'face-api.js';
import { Dimensions } from '../types';
import { MODEL_URL, DETECTION_INTERVAL, DEFAULT_CANVAS_WIDTH, DEFAULT_CANVAS_HEIGHT } from '../constants';

export const useFaceAPI = (
  faceAPICanvasRef: React.RefObject<HTMLCanvasElement>,
  videoRef: React.RefObject<HTMLVideoElement>,
  dimensions: Dimensions
) => {
  const detectionIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const [emotionScore, setEmotionScore] = useState<number>(0);
  const [isModelLoaded, setIsModelLoaded] = useState<boolean>(false);
  const [isCameraReady, setIsCameraReady] = useState<boolean>(false);

  // Î™®Îç∏ Î°úÎìú
  const loadModels = useCallback(async () => {
    try {
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
        faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),
      ]);
      setIsModelLoaded(true);
      console.log('Î™®Îç∏Ïù¥ Î°úÎìúÎêòÏóàÏäµÎãàÎã§');
    } catch (error) {
      console.error('Î™®Îç∏ Î°úÎìú Ï§ë Ïò§Î•ò Î∞úÏÉù:', error);
    }
  }, []);

  // ÌëúÏ†ï Í∞êÏßÄ
  const detectExpressions = useCallback(async () => {
    if (!videoRef.current || !faceAPICanvasRef.current || !isModelLoaded || !isCameraReady) return;
    
    const video = videoRef.current;
    const canvas = faceAPICanvasRef.current;
    
    // Ï∫îÎ≤ÑÏä§ ÌÅ¨Í∏∞Î•º Í≥†Ï†ïÍ∞íÏúºÎ°ú ÏÑ§Ï†ï (ÌôîÎ©¥Ïóê ÌëúÏãúÎêòÏßÄ ÏïäÏúºÎØÄÎ°ú)
    if (canvas.width !== DEFAULT_CANVAS_WIDTH || canvas.height !== DEFAULT_CANVAS_HEIGHT) {
      canvas.width = DEFAULT_CANVAS_WIDTH;
      canvas.height = DEFAULT_CANVAS_HEIGHT;
    }
    
    // ÌëúÏ†ï Í∞êÏßÄÏö©ÏúºÎ°úÎßå ÏÇ¨Ïö©ÌïòÎØÄÎ°ú Í≥†Ï†ï ÌÅ¨Í∏∞Î°ú matchDimensions
    const displaySize = { width: DEFAULT_CANVAS_WIDTH, height: DEFAULT_CANVAS_HEIGHT };
    faceapi.matchDimensions(canvas, displaySize);
    
    try {
      // ÌëúÏ†ï Í∞êÏßÄ Ïã§Ìñâ
      const detections = await faceapi
        .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceExpressions();
      
      if (detections.length > 0) {
        const expressions = detections[0].expressions;
        const happyScore = expressions.happy;
        const sadScore = expressions.sad;
        const angryScore = expressions.angry;
        const disgustedScore = expressions.disgusted;
        const neutralScore = expressions.neutral;
        const surprisedScore = expressions.surprised;
        const fearfulScore = expressions.fearful;
        
        // ÏõÉÏùåÏóê Îçî Ïö∞Ìò∏Ï†ÅÏù∏ Ï†êÏàò Í≥ÑÏÇ∞
        const positiveEmotions = happyScore + (surprisedScore * 0.3); // ÎÜÄÎûåÎèÑ ÏïΩÍ∞Ñ Í∏çÏ†ïÏ†ÅÏúºÎ°ú Í∞ÑÏ£º
        const negativeEmotions = (sadScore + angryScore + disgustedScore + fearfulScore) * 0.7; // Î∂ÄÏ†ïÏ†Å Í∞êÏ†ï Í∞ÄÏ§ëÏπò Í∞êÏÜå
        
        // ÏõÉÏùåÏù¥ Í∞êÏßÄÎêòÎ©¥ Î≥¥ÎÑàÏä§ Ï†êÏàò Ï∂îÍ∞Ä
        let rawScore = positiveEmotions - negativeEmotions;
        if (happyScore > 0.3) {
          rawScore += 0.2; // ÏõÉÏùå Î≥¥ÎÑàÏä§
        }
        
        // Ï§ëÎ¶Ω ÏÉÅÌÉúÎäî ÏïΩÍ∞Ñ Í∏çÏ†ïÏ†ÅÏúºÎ°ú Ï≤òÎ¶¨
        if (neutralScore > 0.5) {
          rawScore += 0.1;
        }
        
        const percentageScore = Math.max(Math.min(rawScore * 100, 100), -100);
        
        // ÏÉÅÏÑ∏Ìïú ÎîîÎ≤ÑÍπÖ Î°úÍ∑∏ (5Ï¥àÎßàÎã§)
        if (Math.abs(Date.now() % 5000) < 100) {
          console.log('üé≠ Í∞êÏ†ï Î∂ÑÏÑù:', {
            ÌñâÎ≥µ: `${(happyScore * 100).toFixed(1)}%`,
            Ïä¨Ìîî: `${(sadScore * 100).toFixed(1)}%`,
            Î∂ÑÎÖ∏: `${(angryScore * 100).toFixed(1)}%`,
            ÌòêÏò§: `${(disgustedScore * 100).toFixed(1)}%`,
            Ï§ëÎ¶Ω: `${(neutralScore * 100).toFixed(1)}%`,
            ÎÜÄÎûå: `${(surprisedScore * 100).toFixed(1)}%`,
            ÎëêÎ†§ÏõÄ: `${(fearfulScore * 100).toFixed(1)}%`,
            ÏµúÏ¢ÖÏ†êÏàò: `${percentageScore.toFixed(1)}%`
          });
        }
        
        setEmotionScore(percentageScore);
      }
    } catch (error) {
      console.warn('ÌëúÏ†ï Í∞êÏßÄ Ï§ë Ïò§Î•ò:', error);
    }
  }, [isModelLoaded, isCameraReady, faceAPICanvasRef, videoRef]);

  // ÌëúÏ†ï Í∞êÏßÄ Ïù∏ÌÑ∞Î≤å ÏãúÏûë
  const startDetectionInterval = useCallback(() => {
    if (detectionIntervalRef.current) {
      clearInterval(detectionIntervalRef.current);
    }
    detectionIntervalRef.current = setInterval(detectExpressions, DETECTION_INTERVAL);
  }, [detectExpressions]);

  // ÌëúÏ†ï Í∞êÏßÄ Ïù∏ÌÑ∞Î≤å Ï§ëÏßÄ
  const stopDetectionInterval = useCallback(() => {
    if (detectionIntervalRef.current) {
      clearInterval(detectionIntervalRef.current);
      detectionIntervalRef.current = null;
    }
  }, []);

  // Ïπ¥Î©îÎùº Ï§ÄÎπÑ ÏÉÅÌÉú ÏÑ§Ï†ï
  const setCameraReady = useCallback((ready: boolean) => {
    setIsCameraReady(ready);
  }, []);

  return {
    emotionScore,
    isModelLoaded,
    isCameraReady,
    loadModels,
    detectExpressions,
    startDetectionInterval,
    stopDetectionInterval,
    setCameraReady
  };
}; 